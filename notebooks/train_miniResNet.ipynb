{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Shallow Network - miniResNet with default RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.layers import Input, Activation, Dropout, Flatten, Dense, add\n",
    "from tensorflow.keras.utils  import to_categorical\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "train_data_dir = '/home/sanchit/Documents/Projects/datasets/fire_and_smoke_data/train/'\n",
    "validation_data_dir = '/home/sanchit/Documents/Projects/datasets/fire_and_smoke_data/val/'\n",
    "nb_train_samples = 2400\n",
    "nb_validation_samples = 490\n",
    "epochs = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniResNet:\n",
    "    \"\"\" mini version of ResNet architecture \"\"\"\n",
    "    \n",
    "    def __init__(self, img_width, img_height):\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        \n",
    "    def __residual_block(self, x, filters, is_reduce_dim=False, reg=0.0001):\n",
    "        shortcut = x \n",
    "        \n",
    "        # pre-activation block, act1 goes as an input to conv1\n",
    "        # first part of the block are 1x1 CONVs with 1/4th of original number of filters\n",
    "        bn1 = BatchNormalization()(x)\n",
    "        act1 = Activation(\"relu\")(bn1)\n",
    "        \n",
    "        if is_reduce_dim:\n",
    "            # convolve (1,1) on the input x which stays as a shortcut to incorporate reduction in dim \n",
    "            shortcut = Conv2D(filters, (1,1), strides=(2,2), use_bias=False, kernel_initializer='he_normal', \n",
    "                              padding=\"same\", kernel_regularizer=l2(reg))(x)\n",
    "            \n",
    "            # first convolution on act1 \n",
    "            conv1 = Conv2D(int(filters*0.25), (1,1), strides=(2,2), use_bias=False, kernel_initializer='he_normal', \n",
    "                           padding=\"same\", kernel_regularizer=l2(reg))(act1)\n",
    "            \n",
    "        else:\n",
    "            shortcut = Conv2D(filters, (1,1), use_bias=False, kernel_initializer='he_normal', \n",
    "                              padding=\"same\", kernel_regularizer=l2(reg))(x)\n",
    "            \n",
    "            conv1 = Conv2D(int(filters*0.25), (1,1), use_bias=False, kernel_initializer='he_normal', \n",
    "                           padding=\"same\", kernel_regularizer=l2(reg))(act1) \n",
    "        \n",
    "        # second part of the block are 3x3 CONVs with 1/4th original number of filters\n",
    "        bn2 = BatchNormalization()(conv1)\n",
    "        act2 = Activation(\"relu\")(bn2)\n",
    "        conv2 = Conv2D(int(filters*0.25), (3,3), use_bias=False, kernel_initializer='he_normal', \n",
    "                       padding=\"same\", kernel_regularizer=l2(reg))(act2)\n",
    "        \n",
    "        # third part of the block are 1x1 CONVs with original number of filters\n",
    "        bn3 = BatchNormalization()(conv2)\n",
    "        act3 = Activation(\"relu\")(bn3)\n",
    "        conv3 = Conv2D(filters, (1,1), use_bias=False, kernel_initializer='he_normal', \n",
    "                       padding=\"same\", kernel_regularizer=l2(reg))(act3)\n",
    "        \n",
    "        # lastly add the shortcut and last output \n",
    "        out = add([shortcut, conv3])\n",
    "        return out\n",
    "        \n",
    "    def build(self):\n",
    "        \n",
    "        input_img = Input(shape=(self.img_width, self.img_height, 3), name='input_image')\n",
    "        \n",
    "        x = Conv2D(16, kernel_size=(3, 3), strides=1, padding='same', \n",
    "                   kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(input_img)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        \n",
    "        x = self.__residual_block(x, 16, is_reduce_dim=False) # 224\n",
    "        x = self.__residual_block(x, 16, is_reduce_dim=True) # 112 \n",
    "        x = self.__residual_block(x, 16, is_reduce_dim=False) # 112\n",
    "        \n",
    "        x = self.__residual_block(x, 32, is_reduce_dim=True) # 56\n",
    "        x = self.__residual_block(x, 32, is_reduce_dim=False) # 56\n",
    "        \n",
    "        x = self.__residual_block(x, 64, is_reduce_dim=True) # 28\n",
    "        x = self.__residual_block(x, 64, is_reduce_dim=False) # 28\n",
    "        \n",
    "        x = self.__residual_block(x, 128, is_reduce_dim=True) # 14\n",
    "        x = self.__residual_block(x, 128, is_reduce_dim=False) # 14\n",
    "        \n",
    "        x = self.__residual_block(x, 256, is_reduce_dim=True) # 7\n",
    "        x = self.__residual_block(x, 256, is_reduce_dim=False) # 7\n",
    "              \n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\", name=\"last_conv_relu\")(x)\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "            \n",
    "        # classifier \n",
    "        x = Flatten()(x)\n",
    "        x = Dense(64, kernel_regularizer=l2(1e-4))(x)\n",
    "        x = Activation(\"relu\", name=\"last_relu\")(x)\n",
    "        x = Dense(1)(x)\n",
    "        output = Activation(\"sigmoid\")(x)\n",
    "        \n",
    "        model = Model(inputs=input_img, outputs=output)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miniResNet = MiniResNet(img_width, img_height)\n",
    "model = miniResNet.build()\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dir_path=\"\", class_mode='binary', classes=None):\n",
    "    \"\"\"\n",
    "    loads all the images for all the classes (sub-dirs) provided in the input directory.\n",
    "    :param dir_path -  input directory which contains for each class a sub-directory. \n",
    "    :param class_mode - binary (for usage in binary_crossentropy loss) and categorical (categorical_crossentropy loss)\n",
    "    :params classes - a list of classes'names \n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    data_kind = dir_path.split(\"/\")[-2] # either training or validation or testing\n",
    "    directories=[d for d in os.listdir(dir_path) if os.path.isdir(d) or (not d.startswith(\".\"))]\n",
    "    \n",
    "    for label, class_name in enumerate(directories):\n",
    "        print(f\"loading {data_kind} data for class: {class_name}\")\n",
    "        class_dir = os.path.join(dir_path, class_name)\n",
    "        for img_path in tqdm(glob(class_dir + '/*.jpg')):\n",
    "            img = load_img(img_path, target_size=(img_width, img_height))\n",
    "            img = img_to_array(img)\n",
    "\n",
    "            # save the image and its corresponding label\n",
    "            X.append(img)\n",
    "            y.append(label)\n",
    "                \n",
    "    X = np.asarray(X, dtype=np.float32) / 255.0\n",
    "    y = np.asarray(y)\n",
    "    \n",
    "    if class_mode == \"categorical\":\n",
    "        y = to_categorical(y_train, num_classes=classes)\n",
    "        \n",
    "    print(f\"total number of images loaded: {X.shape[0]} and of shape: {X.shape[1:]}\")\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_data(dir_path=train_data_dir)\n",
    "X_val, y_val = load_data(dir_path=validation_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\n",
    "    def eraser(input_img):\n",
    "        img_h, img_w, img_c = input_img.shape\n",
    "        p_1 = np.random.rand()\n",
    "\n",
    "        if p_1 > p:\n",
    "            return input_img\n",
    "\n",
    "        while True:\n",
    "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
    "            r = np.random.uniform(r_1, r_2)\n",
    "            w = int(np.sqrt(s / r))\n",
    "            h = int(np.sqrt(s * r))\n",
    "            left = np.random.randint(0, img_w)\n",
    "            top = np.random.randint(0, img_h)\n",
    "\n",
    "            if left + w <= img_w and top + h <= img_h:\n",
    "                break\n",
    "\n",
    "        if pixel_level:\n",
    "            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
    "        else:\n",
    "            c = np.random.uniform(v_l, v_h)\n",
    "\n",
    "        input_img[top:top + h, left:left + w, :] = c\n",
    "\n",
    "        return input_img\n",
    "\n",
    "    return eraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a train generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True, \n",
    "    vertical_flip=True,\n",
    "    rotation_range=30,\n",
    "    fill_mode=\"wrap\",\n",
    "    height_shift_range=0.15,\n",
    "    width_shift_range=0.15)\n",
    "\n",
    "# preprocessing_function=get_random_eraser(v_l=0, v_h=1)\n",
    "\n",
    "# create a test/val generator\n",
    "test_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "validation_generator = test_datagen.flow(X_val, y_val, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size, \n",
    "    workers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = np.arange(0, epochs)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(N, H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(N, H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
