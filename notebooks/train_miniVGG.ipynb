{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Shallow Network - miniVGG style\n",
    "With batch normalization and (optional) random cropping of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "trailing comma not allowed without surrounding parentheses (<ipython-input-2-cfe8f1fb12be>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-cfe8f1fb12be>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array,\u001b[0m\n\u001b[0m                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m trailing comma not allowed without surrounding parentheses\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.layers import Input, Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.utils  import to_categorical\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 224, 224\n",
    "train_data_dir = '/home/sanchit/Documents/Projects/datasets/fire_and_smoke_data/train/'\n",
    "validation_data_dir = '/home/sanchit/Documents/Projects/datasets/fire_and_smoke_data/val/'\n",
    "nb_train_samples = 2400\n",
    "nb_validation_samples = 490\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "model_path = \"./models/cust_network.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "input_shape = (img_width, img_height, 3)\n",
    "model.add(Conv2D(32, (3, 3), padding='same', kernel_initializer='he_normal', \n",
    "                 kernel_regularizer=l2(1e-4), input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', strides=2, kernel_initializer='he_normal', \n",
    "                 kernel_regularizer=l2(1e-4), input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', kernel_initializer='he_normal', \n",
    "                 kernel_regularizer=l2(1e-4), input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', strides=2, kernel_initializer='he_normal', \n",
    "                 kernel_regularizer=l2(1e-4), input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', kernel_initializer='he_normal', \n",
    "                 kernel_regularizer=l2(1e-4), input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', strides=2, kernel_initializer='he_normal', \n",
    "                 kernel_regularizer=l2(1e-4), input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal', \n",
    "                 kernel_regularizer=l2(1e-4), input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', strides=2, kernel_initializer='he_normal', \n",
    "                 kernel_regularizer=l2(1e-4), input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal', \n",
    "                 kernel_regularizer=l2(1e-4), input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', strides=2, kernel_initializer='he_normal', \n",
    "                 kernel_regularizer=l2(1e-4), input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True, \n",
    "    vertical_flip=True, \n",
    "    brightness_range=[0.6, 1.3])\n",
    "\n",
    "# this is the augmentation configuration we will use for testing: only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define callbacks before starting the training\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=10, mode=\"min\", verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(model_path, monitor=\"val_acc\", save_best_only=True, mode='max', verbose=1)\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard = TensorBoard(log_dir=logdir, histogram_freq=1)\n",
    "callbacks = [early_stop, model_checkpoint, tensorboard]\n",
    "\n",
    "H = model.fit_generator(train_generator, \n",
    "                        steps_per_epoch=nb_train_samples // batch_size, \n",
    "                        epochs=epochs,\n",
    "                        validation_data=validation_generator,\n",
    "                        validation_steps=nb_validation_samples // batch_size, \n",
    "                        callbacks = callbacks)\n",
    "\n",
    "# launch TensorBoard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
