{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find a learning rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.models import Model, Sequential \n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.layers import Input, Activation, Dropout, Flatten, Dense, add\n",
    "from tensorflow.keras.utils  import to_categorical\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K \n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import tempfile \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "train_data_dir = '/home/sanchit/Documents/Projects/datasets/fire_and_smoke_data/train/'\n",
    "validation_data_dir = '/home/sanchit/Documents/Projects/datasets/fire_and_smoke_data/val/'\n",
    "nb_train_samples = 2400\n",
    "nb_validation_samples = 490\n",
    "epochs = 30\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build a network - copy and paste your networ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "input_shape = (img_width, img_height, 3)\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compile a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 222, 222, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 109, 109, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 109, 109, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 52, 52, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 52, 52, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 10, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 3, 128)         147584    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 295,329\n",
      "Trainable params: 295,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sgd = SGD(momentum=0.9)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dir_path=\"\", class_mode='binary', classes=None):\n",
    "    \"\"\"\n",
    "    loads all the images for all the classes (sub-dirs) provided in the input directory.\n",
    "    :param dir_path -  input directory which contains for each class a sub-directory. \n",
    "    :param class_mode - binary (for usage in binary_crossentropy loss) and categorical (categorical_crossentropy loss)\n",
    "    :params classes - a list of classes'names \n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    data_kind = dir_path.split(\"/\")[-2] # either training or validation or testing\n",
    "    directories=[d for d in os.listdir(dir_path) if os.path.isdir(d) or (not d.startswith(\".\"))]\n",
    "    \n",
    "    for label, class_name in enumerate(directories):\n",
    "        print(f\"loading {data_kind} data for class: {class_name}\")\n",
    "        class_dir = os.path.join(dir_path, class_name)\n",
    "        for img_path in tqdm(glob(class_dir + '/*.jpg')):\n",
    "            img = load_img(img_path, target_size=(img_width, img_height))\n",
    "            img = img_to_array(img)\n",
    "\n",
    "            # save the image and its corresponding label\n",
    "            X.append(img)\n",
    "            y.append(label)\n",
    "                \n",
    "    X = np.asarray(X, dtype=np.float32) / 255.0\n",
    "    y = np.asarray(y)\n",
    "    \n",
    "    if class_mode == \"categorical\":\n",
    "        y = to_categorical(y_train, num_classes=classes)\n",
    "        \n",
    "    print(f\"total number of images loaded: {X.shape[0]} and of shape: {X.shape[1:]}\")\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 22/1200 [00:00<00:05, 205.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train data for class: fire\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 418/1200 [00:03<00:06, 129.80it/s]/home/sanchit/miniconda3/envs/tf2.1/lib/python3.7/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|██████████| 1200/1200 [00:09<00:00, 129.66it/s]\n",
      "  2%|▏         | 21/1200 [00:00<00:05, 196.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train data for class: no_fire\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:09<00:00, 132.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of images loaded: 2400 and of shape: (224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = load_data(dir_path=train_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a train generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True, \n",
    "    vertical_flip=True,\n",
    "    rotation_range=30,\n",
    "    fill_mode=\"wrap\",\n",
    "    height_shift_range=0.15,\n",
    "    width_shift_range=0.15)\n",
    "\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the best learning rates range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningRateFinder:\n",
    "    \"\"\" Objective is to find a best learning rate by plotting various losses against a list of learning \n",
    "    rates which range from very high to very low. Optimal LR should lie somewhere inside of this range. \n",
    "    \n",
    "    Starting and ending LRs which are chosen are too low (where network is unable to learn, thus a high \n",
    "    loss and too high (where loss is also high), respectively). Therefore, a good range of min and max LR \n",
    "    bounds should be somewhere inside of this range and finding that good range is the objective of this class. \n",
    "    \n",
    "    At the end, entire network can be then trained by using either the correct LR (min LR) or min and max LRs \n",
    "    with a Cyclic LR scheduler. \n",
    "    \n",
    "    Reference: https://www.pyimagesearch.com/2019/08/05/keras-learning-rate-finder/\n",
    "    \"\"\"\n",
    "    def __init__(self, model, stopFactor=4, beta=0.98):\n",
    "        \"\"\" initializes variables for finding the LRs \n",
    "            \n",
    "            :param model: model for which LRs and losses are plotted and analyzed \n",
    "            :param stopFactor: stop factor when the LR becomes too large, then stop the model training automatically \n",
    "            :param beta: used for averaging the loss value \n",
    "            :param lrs: a list of tried LR values \n",
    "            :param losses: a list of tried loss values \n",
    "            :param avgLoss: average loss value over time \n",
    "            :param batchNum: current batch number \n",
    "            :param bestLoss: best loss (of course, lowest) found so far during training \n",
    "            :param lrMult: LR multiplication factor \n",
    "            :weightsFile: filename to save initial (original) weights of the model \n",
    "        \"\"\"\n",
    "        \n",
    "        # store the model, stop factor, and beta value (for computing\n",
    "        # a smoothed, average loss)\n",
    "        self.model = model\n",
    "        self.stopFactor = stopFactor\n",
    "        self.beta = beta\n",
    "\n",
    "        # initialize our list of learning rates and losses,\n",
    "        # respectively\n",
    "        self.lrs = []\n",
    "        self.losses = []\n",
    "\n",
    "        # initialize our learning rate multiplier, average loss, best\n",
    "        # loss found thus far, current batch number, and weights file\n",
    "        self.lrMult = 1\n",
    "        self.avgLoss = 0\n",
    "        self.bestLoss = 1e9\n",
    "        self.batchNum = 0\n",
    "        self.weightsFile = None\n",
    "\n",
    "    def reset(self):\n",
    "        # re-initialize all variables from our constructor\n",
    "        self.lrs = []\n",
    "        self.losses = []\n",
    "        self.lrMult = 1\n",
    "        self.avgLoss = 0\n",
    "        self.bestLoss = 1e9\n",
    "        self.batchNum = 0\n",
    "        self.weightsFile = None\n",
    "\n",
    "    def is_data_iter(self, data):\n",
    "        # define the set of class types we will check for\n",
    "        iterClasses = [\"NumpyArrayIterator\", \"DirectoryIterator\",\n",
    "             \"DataFrameIterator\", \"Iterator\", \"Sequence\"]\n",
    "\n",
    "        # return whether our data is an iterator\n",
    "        return data.__class__.__name__ in iterClasses\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        \"\"\" following are the steps/things which is happening in this function:\n",
    "            - this function runs after every batch update \n",
    "            - recording of current loss values which is smoothen up first \n",
    "            - recording of best loss and updating of it if a new one has been found \n",
    "            - checking if the loss has grown too much, then stop the model training \n",
    "            - setting up of a new LR for the next model training with multiplying current \n",
    "              LR with the LR-multiplier at every batch update\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        # get the current LR from the model and save to a list of LRs which have been used already \n",
    "        lr = K.get_value(self.model.optimizer.lr)\n",
    "        self.lrs.append(lr)\n",
    "\n",
    "        # grab the loss at the end of this batch, increment the total\n",
    "        # number of batches processed, compute the average average\n",
    "        # loss, smooth it, and update the losses list with the\n",
    "        # smoothed value\n",
    "        l = logs[\"loss\"] # NOTE: it contains the current loss of the training\n",
    "        self.batchNum += 1\n",
    "        self.avgLoss = (self.beta * self.avgLoss) + ((1 - self.beta) * l)\n",
    "        smooth = self.avgLoss / (1 - (self.beta ** self.batchNum))\n",
    "        self.losses.append(smooth)\n",
    "\n",
    "        # compute the maximum loss stopping factor value\n",
    "        stopLoss = self.stopFactor * self.bestLoss\n",
    "\n",
    "        # check to see whether the loss has grown too large\n",
    "        if self.batchNum > 1 and smooth > stopLoss:\n",
    "            # stop returning and return from the method\n",
    "            self.model.stop_training = True\n",
    "            return\n",
    "\n",
    "        # check to see if the best loss should be updated\n",
    "        if self.batchNum == 1 or smooth < self.bestLoss:\n",
    "            self.bestLoss = smooth\n",
    "\n",
    "        # increase the learning rate ans set it as a new LR for the model training \n",
    "        lr *= self.lrMult # self.lrMult is found in the find() method\n",
    "        K.set_value(self.model.optimizer.lr, lr)\n",
    "\n",
    "    def find(self, trainData, startLR, endLR, epochs=None,\n",
    "        stepsPerEpoch=None, batchSize=32, sampleSize=2048,\n",
    "        classWeight=None, verbose=1):\n",
    "        \"\"\" following are the steps/things which is happening in this function:\n",
    "            - only using the training data for computing the loss, i.e., no split of it into test/val data \n",
    "            - loss log are transferred via LambdaCallback function to \"on_batch_end()\" fn. \n",
    "            - LR multiplier is computed once. And, it is a fixed (uniform) interval computed from endLR, startLR \n",
    "                over total numbers of batches \n",
    "            - Model's original weights and LR are temporarily saved and they get imported back again after \n",
    "              the plot for finding the best LR is done. \n",
    "        \"\"\"\n",
    "        \n",
    "        # reset our class-specific variables\n",
    "        self.reset()\n",
    "\n",
    "        # determine if we are using a data generator or not\n",
    "        useGen = self.is_data_iter(trainData)\n",
    "\n",
    "        # if we're using a generator and the steps per epoch is not\n",
    "        # supplied, raise an error\n",
    "        if useGen and stepsPerEpoch is None:\n",
    "            msg = \"Using generator without supplying stepsPerEpoch\"\n",
    "            raise Exception(msg)\n",
    "\n",
    "        # if we're not using a generator then our entire dataset must\n",
    "        # already be in memory\n",
    "        elif not useGen:\n",
    "            # grab the number of samples in the training data and\n",
    "            # then derive the number of steps per epoch\n",
    "            numSamples = len(trainData[0])\n",
    "            stepsPerEpoch = np.ceil(numSamples / float(batchSize))\n",
    "\n",
    "        # if no number of training epochs are supplied, compute the\n",
    "        # training epochs based on a default sample size\n",
    "        if epochs is None:\n",
    "            epochs = int(np.ceil(sampleSize / float(stepsPerEpoch)))\n",
    "\n",
    "        # compute the total number of batch updates that will take\n",
    "        # place while we are attempting to find a good starting\n",
    "        # learning rate\n",
    "        numBatchUpdates = epochs * stepsPerEpoch\n",
    "\n",
    "        # derive the learning rate multiplier based on the ending\n",
    "        # learning rate, starting learning rate, and total number of\n",
    "        # batch updates\n",
    "        self.lrMult = (endLR / startLR) ** (1.0 / numBatchUpdates)\n",
    "\n",
    "        # save the model's original weights, so we can reset the weights when we are \n",
    "        # done finiding the optimal learning rates \n",
    "        self.weightsFile = tempfile.mkstemp()[1]\n",
    "        self.model.save_weights(self.weightsFile)\n",
    "\n",
    "        # grab the *original* learning rate (so we can reset it\n",
    "        # later), and then set the *starting* learning rate\n",
    "        origLR = K.get_value(self.model.optimizer.lr)\n",
    "        K.set_value(self.model.optimizer.lr, startLR)\n",
    "\n",
    "        # construct a callback that will be called at the end of each\n",
    "        # batch, enabling us to increase our learning rate as training\n",
    "        # progresses\n",
    "        callback = LambdaCallback(on_batch_end=lambda batch, logs:\n",
    "            self.on_batch_end(batch, logs))\n",
    "\n",
    "        # check to see if we are using a data iterator\n",
    "        if useGen:\n",
    "            self.model.fit_generator(\n",
    "                trainData,\n",
    "                steps_per_epoch=stepsPerEpoch,\n",
    "                epochs=epochs,\n",
    "                class_weight=classWeight,\n",
    "                verbose=verbose,\n",
    "                callbacks=[callback],\n",
    "                workers=8)\n",
    "\n",
    "        # otherwise, our entire training data is already in memory\n",
    "        else:\n",
    "            # train our model using Keras' fit method\n",
    "            self.model.fit(\n",
    "                trainData[0], trainData[1],\n",
    "                batch_size=batchSize,\n",
    "                epochs=epochs,\n",
    "                class_weight=classWeight,\n",
    "                callbacks=[callback],\n",
    "                verbose=verbose,\n",
    "                workers=8)\n",
    "\n",
    "        # finally, when we are done, set back the original model's weights and LR values \n",
    "        self.model.load_weights(self.weightsFile)\n",
    "        K.set_value(self.model.optimizer.lr, origLR)\n",
    "\n",
    "    def plot_loss(self, skipBegin=10, skipEnd=1, title=\"\"):\n",
    "        # grab the learning rate and losses values to plot\n",
    "        lrs = self.lrs[skipBegin:-skipEnd]\n",
    "        losses = self.losses[skipBegin:-skipEnd]\n",
    "\n",
    "        # plot the learning rate vs. loss\n",
    "        plt.plot(lrs, losses)\n",
    "        plt.xscale(\"log\")\n",
    "        plt.xlabel(\"Learning Rate (Log Scale)\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "\n",
    "        # if the title is not empty, add it to the plot\n",
    "        if title != \"\":\n",
    "            plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-06fd8943f1a3>:180: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 75 steps\n",
      "Epoch 1/30\n",
      "75/75 [==============================] - 4s 52ms/step - loss: 0.6918 - accuracy: 0.5171\n",
      "Epoch 2/30\n",
      "75/75 [==============================] - 3s 42ms/step - loss: 0.6924 - accuracy: 0.5096\n",
      "Epoch 3/30\n",
      "75/75 [==============================] - 3s 41ms/step - loss: 0.6920 - accuracy: 0.5063\n",
      "Epoch 4/30\n",
      "75/75 [==============================] - 3s 42ms/step - loss: 0.6918 - accuracy: 0.5063\n",
      "Epoch 5/30\n",
      "75/75 [==============================] - 3s 43ms/step - loss: 0.6922 - accuracy: 0.5163\n",
      "Epoch 6/30\n",
      "75/75 [==============================] - 3s 41ms/step - loss: 0.6919 - accuracy: 0.5163\n",
      "Epoch 7/30\n",
      "75/75 [==============================] - 3s 42ms/step - loss: 0.6929 - accuracy: 0.5121\n",
      "Epoch 8/30\n",
      "75/75 [==============================] - 3s 42ms/step - loss: 0.6924 - accuracy: 0.5058\n",
      "Epoch 9/30\n",
      "75/75 [==============================] - 3s 41ms/step - loss: 0.6922 - accuracy: 0.5113\n",
      "Epoch 10/30\n",
      "75/75 [==============================] - 3s 41ms/step - loss: 0.6926 - accuracy: 0.5038\n",
      "Epoch 11/30\n",
      "75/75 [==============================] - 3s 43ms/step - loss: 0.6930 - accuracy: 0.5038\n",
      "Epoch 12/30\n",
      "75/75 [==============================] - 3s 42ms/step - loss: 0.6920 - accuracy: 0.5146\n",
      "Epoch 13/30\n",
      "75/75 [==============================] - 3s 40ms/step - loss: 0.6923 - accuracy: 0.5083\n",
      "Epoch 14/30\n",
      "75/75 [==============================] - 3s 40ms/step - loss: 0.6919 - accuracy: 0.5204\n",
      "Epoch 15/30\n",
      "75/75 [==============================] - 3s 42ms/step - loss: 0.6922 - accuracy: 0.5171\n",
      "Epoch 16/30\n",
      "75/75 [==============================] - 3s 42ms/step - loss: 0.6922 - accuracy: 0.4938\n",
      "Epoch 17/30\n",
      "75/75 [==============================] - 3s 42ms/step - loss: 0.6917 - accuracy: 0.5163\n",
      "Epoch 18/30\n",
      "75/75 [==============================] - 3s 42ms/step - loss: 0.6910 - accuracy: 0.5217\n",
      "Epoch 19/30\n",
      "75/75 [==============================] - 3s 42ms/step - loss: 0.6909 - accuracy: 0.5317\n",
      "Epoch 20/30\n",
      "75/75 [==============================] - 3s 41ms/step - loss: 0.6881 - accuracy: 0.5571\n",
      "Epoch 21/30\n",
      "75/75 [==============================] - 3s 44ms/step - loss: 0.6812 - accuracy: 0.6071\n",
      "Epoch 22/30\n",
      "75/75 [==============================] - 3s 43ms/step - loss: 0.6491 - accuracy: 0.6358\n",
      "Epoch 23/30\n",
      "75/75 [==============================] - 3s 40ms/step - loss: 0.6539 - accuracy: 0.6171\n",
      "Epoch 24/30\n",
      "75/75 [==============================] - 3s 43ms/step - loss: 0.6235 - accuracy: 0.6454\n",
      "Epoch 25/30\n",
      "75/75 [==============================] - 3s 43ms/step - loss: 0.6735 - accuracy: 0.5617\n",
      "Epoch 26/30\n",
      "75/75 [==============================] - 3s 41ms/step - loss: 0.7000 - accuracy: 0.5317\n",
      "Epoch 27/30\n",
      "75/75 [==============================] - 3s 40ms/step - loss: 0.6986 - accuracy: 0.5100\n",
      "Epoch 28/30\n",
      "75/75 [==============================] - 3s 41ms/step - loss: 0.7076 - accuracy: 0.4917\n",
      "Epoch 29/30\n",
      "75/75 [==============================] - 3s 44ms/step - loss: 0.7312 - accuracy: 0.5050\n",
      "Epoch 30/30\n",
      "75/75 [==============================] - 3s 41ms/step - loss: 1.0654 - accuracy: 0.5067\n",
      "[INFO] learning rate finder complete\n",
      "[INFO] examine plot and adjust learning rates before training\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanchit/miniconda3/envs/tf2.1/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrf = LearningRateFinder(model)\n",
    "# increasing learning rates at a regular interval from a very low to very high range. Then, compute \n",
    "# the training loss. Objective here is to find a range of LRs where the loss varies the most. That means in those \n",
    "# LRs model is the learning the most. \n",
    "lrf.find(train_generator, \n",
    "        startLR=1e-10, \n",
    "        endLR=1e+1, \n",
    "        epochs=30,\n",
    "        stepsPerEpoch=nb_train_samples // batch_size, \n",
    "        batchSize=batch_size)\n",
    "\n",
    "# plot the loss for the various learning rates and save the\n",
    "# resulting plot to disk\n",
    "lrf.plot_loss()\n",
    "#plt.savefig(LR_LOSS_PLOT_PATH)\n",
    "\n",
    "# exit the script so we can adjust our learning rates\n",
    "# in the config and then train the network for our full set of\n",
    "# epochs\n",
    "print(\"[INFO] learning rate finder complete\")\n",
    "print(\"[INFO] examine plot and adjust learning rates before training\")\n",
    "sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\n",
    "#     def eraser(input_img):\n",
    "#         img_h, img_w, img_c = input_img.shape\n",
    "#         p_1 = np.random.rand()\n",
    "\n",
    "#         if p_1 > p:\n",
    "#             return input_img\n",
    "\n",
    "#         while True:\n",
    "#             s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
    "#             r = np.random.uniform(r_1, r_2)\n",
    "#             w = int(np.sqrt(s / r))\n",
    "#             h = int(np.sqrt(s * r))\n",
    "#             left = np.random.randint(0, img_w)\n",
    "#             top = np.random.randint(0, img_h)\n",
    "\n",
    "#             if left + w <= img_w and top + h <= img_h:\n",
    "#                 break\n",
    "\n",
    "#         if pixel_level:\n",
    "#             c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
    "#         else:\n",
    "#             c = np.random.uniform(v_l, v_h)\n",
    "\n",
    "#         input_img[top:top + h, left:left + w, :] = c\n",
    "\n",
    "#         return input_img\n",
    "\n",
    "#     return eraser"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
