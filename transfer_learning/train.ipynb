{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D, Activation\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import LambdaCallback, TensorBoard\n",
    "from tensorflow.keras import backend as K \n",
    "import tempfile \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration parameters \n",
    "TRAIN_DATA_DIR = '/Users/sanchit/Documents/Projects/Datasets/fire_and_smoke_data/train/'\n",
    "VALIDATION_DATA_DIR = '/Users/sanchit/Documents/Projects/Datasets/fire_and_smoke_data/val/'\n",
    "TEST_DATA_DIR = '/Users/sanchit/Documents/Projects/Datasets/fire_and_smoke_data/test/'\n",
    "MODEL_PATH = \"./models/mobilenetv2_.h5\"\n",
    "TRAIN_SAMPLES = 2400\n",
    "VALIDATION_SAMPLES = 490\n",
    "TEST_SAMPLES = 490\n",
    "NUM_CLASSES = 2\n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 7\n",
    "LABELS = [\"fire\", \"nofire\"]\n",
    "LR_LOSS_PLOT_PATH = \"./models/lr_loss_plot.png\"\n",
    "INIT_LR = 0.01 # this needs to be set as the max LR from the finding LR plot\n",
    "FIND_LR_ENABLE = False # at first set it always to true to find out the best LRs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data generators\n",
    "create data generators for both training and validation sets and apply data augmentation only to training generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2400 images belonging to 2 classes.\n",
      "Found 490 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# create training data generator and initialize it with data augmentation methods \n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input, \n",
    "                                   horizontal_flip=True, \n",
    "                                   vertical_flip=True,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   brightness_range=[0.6, 1.3],\n",
    "                                   rotation_range=90, \n",
    "                                   zoom_range=0.15, fill_mode=\"reflect\")\n",
    "\n",
    "# and validation data generator\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DATA_DIR,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=12345,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    VALIDATION_DATA_DIR,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model \n",
    "we are using transfer learning for training our model, therefore, freeze the main layers of the model and attach a new custom F.C. classifier on the top of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a model \n",
    "def create_model():\n",
    "    base_model = MobileNetV2(include_top=False, \n",
    "                              input_shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "    \n",
    "    for layer in base_model.layers[:]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    input_layer = base_model.output \n",
    "    x = GlobalAveragePooling2D()(input_layer)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(NUM_CLASSES, name=\"last_dense\")(x)\n",
    "    output = Activation(\"softmax\", name=\"last_softmax\")(x)\n",
    "    #output = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "    \n",
    "    # create the final model \n",
    "    model = Model(inputs = base_model.input, outputs = output)\n",
    "    model.summary()\n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_pad (ZeroPadding2D)       (None, 225, 225, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, 112, 112, 32) 864         Conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalization)   (None, 112, 112, 32) 128         Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)               (None, 112, 112, 32) 0           bn_Conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (Depthw (None, 112, 112, 32) 288         Conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (Bat (None, 112, 112, 32) 128         expanded_conv_depthwise[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (R (None, 112, 112, 32) 0           expanded_conv_depthwise_BN[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)  (None, 112, 112, 16) 512         expanded_conv_depthwise_relu[0][0\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (Batch (None, 112, 112, 16) 64          expanded_conv_project[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)         (None, 112, 112, 96) 1536        expanded_conv_project_BN[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormali (None, 112, 112, 96) 384         block_1_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)      (None, 112, 112, 96) 0           block_1_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_pad (ZeroPadding2D)     (None, 113, 113, 96) 0           block_1_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseCon (None, 56, 56, 96)   864         block_1_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNorm (None, 56, 56, 96)   384         block_1_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)   (None, 56, 56, 96)   0           block_1_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)        (None, 56, 56, 24)   2304        block_1_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project_BN (BatchNormal (None, 56, 56, 24)   96          block_1_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)         (None, 56, 56, 144)  3456        block_1_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_2_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_2_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise (DepthwiseCon (None, 56, 56, 144)  1296        block_2_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_BN (BatchNorm (None, 56, 56, 144)  576         block_2_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_relu (ReLU)   (None, 56, 56, 144)  0           block_2_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project (Conv2D)        (None, 56, 56, 24)   3456        block_2_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project_BN (BatchNormal (None, 56, 56, 24)   96          block_2_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_add (Add)               (None, 56, 56, 24)   0           block_1_project_BN[0][0]         \n",
      "                                                                 block_2_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand (Conv2D)         (None, 56, 56, 144)  3456        block_2_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_3_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_3_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_pad (ZeroPadding2D)     (None, 57, 57, 144)  0           block_3_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise (DepthwiseCon (None, 28, 28, 144)  1296        block_3_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_BN (BatchNorm (None, 28, 28, 144)  576         block_3_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_relu (ReLU)   (None, 28, 28, 144)  0           block_3_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project (Conv2D)        (None, 28, 28, 32)   4608        block_3_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project_BN (BatchNormal (None, 28, 28, 32)   128         block_3_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand (Conv2D)         (None, 28, 28, 192)  6144        block_3_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_4_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_4_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_4_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_4_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_4_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project (Conv2D)        (None, 28, 28, 32)   6144        block_4_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project_BN (BatchNormal (None, 28, 28, 32)   128         block_4_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_add (Add)               (None, 28, 28, 32)   0           block_3_project_BN[0][0]         \n",
      "                                                                 block_4_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand (Conv2D)         (None, 28, 28, 192)  6144        block_4_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_5_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_5_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_5_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_5_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_5_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project (Conv2D)        (None, 28, 28, 32)   6144        block_5_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project_BN (BatchNormal (None, 28, 28, 32)   128         block_5_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_5_add (Add)               (None, 28, 28, 32)   0           block_4_add[0][0]                \n",
      "                                                                 block_5_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand (Conv2D)         (None, 28, 28, 192)  6144        block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_6_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_6_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_pad (ZeroPadding2D)     (None, 29, 29, 192)  0           block_6_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise (DepthwiseCon (None, 14, 14, 192)  1728        block_6_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_BN (BatchNorm (None, 14, 14, 192)  768         block_6_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_relu (ReLU)   (None, 14, 14, 192)  0           block_6_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project (Conv2D)        (None, 14, 14, 64)   12288       block_6_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project_BN (BatchNormal (None, 14, 14, 64)   256         block_6_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand (Conv2D)         (None, 14, 14, 384)  24576       block_6_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_7_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_7_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_7_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_7_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_7_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project (Conv2D)        (None, 14, 14, 64)   24576       block_7_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project_BN (BatchNormal (None, 14, 14, 64)   256         block_7_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_add (Add)               (None, 14, 14, 64)   0           block_6_project_BN[0][0]         \n",
      "                                                                 block_7_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand (Conv2D)         (None, 14, 14, 384)  24576       block_7_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_8_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_8_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_8_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_8_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_8_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project (Conv2D)        (None, 14, 14, 64)   24576       block_8_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project_BN (BatchNormal (None, 14, 14, 64)   256         block_8_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_8_add (Add)               (None, 14, 14, 64)   0           block_7_add[0][0]                \n",
      "                                                                 block_8_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand (Conv2D)         (None, 14, 14, 384)  24576       block_8_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_9_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_9_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_9_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_9_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_9_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project (Conv2D)        (None, 14, 14, 64)   24576       block_9_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project_BN (BatchNormal (None, 14, 14, 64)   256         block_9_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_9_add (Add)               (None, 14, 14, 64)   0           block_8_add[0][0]                \n",
      "                                                                 block_9_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand (Conv2D)        (None, 14, 14, 384)  24576       block_9_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_BN (BatchNormal (None, 14, 14, 384)  1536        block_10_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_relu (ReLU)     (None, 14, 14, 384)  0           block_10_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise (DepthwiseCo (None, 14, 14, 384)  3456        block_10_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_BN (BatchNor (None, 14, 14, 384)  1536        block_10_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           block_10_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project (Conv2D)       (None, 14, 14, 96)   36864       block_10_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project_BN (BatchNorma (None, 14, 14, 96)   384         block_10_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand (Conv2D)        (None, 14, 14, 576)  55296       block_10_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_11_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_11_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_11_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_11_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_11_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project (Conv2D)       (None, 14, 14, 96)   55296       block_11_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project_BN (BatchNorma (None, 14, 14, 96)   384         block_11_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_add (Add)              (None, 14, 14, 96)   0           block_10_project_BN[0][0]        \n",
      "                                                                 block_11_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand (Conv2D)        (None, 14, 14, 576)  55296       block_11_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_12_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_12_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_12_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_12_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_12_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project (Conv2D)       (None, 14, 14, 96)   55296       block_12_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project_BN (BatchNorma (None, 14, 14, 96)   384         block_12_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_12_add (Add)              (None, 14, 14, 96)   0           block_11_add[0][0]               \n",
      "                                                                 block_12_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand (Conv2D)        (None, 14, 14, 576)  55296       block_12_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_13_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_13_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_pad (ZeroPadding2D)    (None, 15, 15, 576)  0           block_13_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise (DepthwiseCo (None, 7, 7, 576)    5184        block_13_pad[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_BN (BatchNor (None, 7, 7, 576)    2304        block_13_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)    0           block_13_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project (Conv2D)       (None, 7, 7, 160)    92160       block_13_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project_BN (BatchNorma (None, 7, 7, 160)    640         block_13_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand (Conv2D)        (None, 7, 7, 960)    153600      block_13_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_14_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_14_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_14_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_14_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_14_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project (Conv2D)       (None, 7, 7, 160)    153600      block_14_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project_BN (BatchNorma (None, 7, 7, 160)    640         block_14_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_add (Add)              (None, 7, 7, 160)    0           block_13_project_BN[0][0]        \n",
      "                                                                 block_14_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand (Conv2D)        (None, 7, 7, 960)    153600      block_14_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_15_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_15_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_15_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_15_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_15_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project (Conv2D)       (None, 7, 7, 160)    153600      block_15_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project_BN (BatchNorma (None, 7, 7, 160)    640         block_15_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_15_add (Add)              (None, 7, 7, 160)    0           block_14_add[0][0]               \n",
      "                                                                 block_15_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand (Conv2D)        (None, 7, 7, 960)    153600      block_15_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_16_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_16_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_16_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_16_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_16_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project (Conv2D)       (None, 7, 7, 320)    307200      block_16_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project_BN (BatchNorma (None, 7, 7, 320)    1280        block_16_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 7, 7, 1280)   409600      block_16_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)   5120        Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "out_relu (ReLU)                 (None, 7, 7, 1280)   0           Conv_1_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 1280)         0           out_relu[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           81984       global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "last_dense (Dense)              (None, 2)            130         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "last_softmax (Activation)       (None, 2)            0           last_dense[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 2,340,098\n",
      "Trainable params: 82,114\n",
      "Non-trainable params: 2,257,984\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create model \n",
    "model = create_model()\n",
    "\n",
    "# choose an optimize. Note for finding the best LR, it does not matter what lr is set \n",
    "# here! because during the best LR search, it will going to set its own LRs, however, at the end, \n",
    "# it will set back this original LRs. \n",
    "opt = tf.keras.optimizers.Adam(lr=INIT_LR)\n",
    "#opt = tf.keras.optimizers.SGD(momentum=0.9)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the best learning rates range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningRateFinder:\n",
    "    \"\"\" Objective is to find a best learning rate by plotting various losses against a list of learning \n",
    "    rates which range from very high to very low. Optimal LR should lie somewhere inside of this range. \n",
    "    \n",
    "    Starting and ending LRs which are chosen are too low (where network is unable to learn, thus a high \n",
    "    loss and too high (where loss is also high), respectively). Therefore, a good range of min and max LR \n",
    "    bounds should be somewhere inside of this range and finding that good range is the objective of this class. \n",
    "    \n",
    "    At the end, entire network can be then trained by using either the correct LR (min LR) or min and max LRs \n",
    "    with a Cyclic LR scheduler. \n",
    "    \n",
    "    Reference: https://www.pyimagesearch.com/2019/08/05/keras-learning-rate-finder/\n",
    "    \"\"\"\n",
    "    def __init__(self, model, stopFactor=4, beta=0.98):\n",
    "        \"\"\" initializes variables for finding the LRs \n",
    "            \n",
    "            :param model: model for which LRs and losses are plotted and analyzed \n",
    "            :param stopFactor: stop factor when the LR becomes too large, then stop the model training automatically \n",
    "            :param beta: used for averaging the loss value \n",
    "            :param lrs: a list of tried LR values \n",
    "            :param losses: a list of tried loss values \n",
    "            :param avgLoss: average loss value over time \n",
    "            :param batchNum: current batch number \n",
    "            :param bestLoss: best loss (of course, lowest) found so far during training \n",
    "            :param lrMult: LR multiplication factor \n",
    "            :weightsFile: filename to save initial (original) weights of the model \n",
    "        \"\"\"\n",
    "        \n",
    "        # store the model, stop factor, and beta value (for computing\n",
    "        # a smoothed, average loss)\n",
    "        self.model = model\n",
    "        self.stopFactor = stopFactor\n",
    "        self.beta = beta\n",
    "\n",
    "        # initialize our list of learning rates and losses,\n",
    "        # respectively\n",
    "        self.lrs = []\n",
    "        self.losses = []\n",
    "\n",
    "        # initialize our learning rate multiplier, average loss, best\n",
    "        # loss found thus far, current batch number, and weights file\n",
    "        self.lrMult = 1\n",
    "        self.avgLoss = 0\n",
    "        self.bestLoss = 1e9\n",
    "        self.batchNum = 0\n",
    "        self.weightsFile = None\n",
    "\n",
    "    def reset(self):\n",
    "        # re-initialize all variables from our constructor\n",
    "        self.lrs = []\n",
    "        self.losses = []\n",
    "        self.lrMult = 1\n",
    "        self.avgLoss = 0\n",
    "        self.bestLoss = 1e9\n",
    "        self.batchNum = 0\n",
    "        self.weightsFile = None\n",
    "\n",
    "    def is_data_iter(self, data):\n",
    "        # define the set of class types we will check for\n",
    "        iterClasses = [\"NumpyArrayIterator\", \"DirectoryIterator\",\n",
    "             \"DataFrameIterator\", \"Iterator\", \"Sequence\"]\n",
    "\n",
    "        # return whether our data is an iterator\n",
    "        return data.__class__.__name__ in iterClasses\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        \"\"\" following are the steps/things which is happening in this function:\n",
    "            - this function runs after every batch update \n",
    "            - recording of current loss values which is smoothen up first \n",
    "            - recording of best loss and updating of it if a new one has been found \n",
    "            - checking if the loss has grown too much, then stop the model training \n",
    "            - setting up of a new LR for the next model training with multiplying current \n",
    "              LR with the LR-multiplier at every batch update\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        # get the current LR from the model and save to a list of LRs which have been used already \n",
    "        lr = K.get_value(self.model.optimizer.lr)\n",
    "        self.lrs.append(lr)\n",
    "\n",
    "        # grab the loss at the end of this batch, increment the total\n",
    "        # number of batches processed, compute the average average\n",
    "        # loss, smooth it, and update the losses list with the\n",
    "        # smoothed value\n",
    "        l = logs[\"loss\"] # NOTE: it contains the current loss of the training\n",
    "        self.batchNum += 1\n",
    "        self.avgLoss = (self.beta * self.avgLoss) + ((1 - self.beta) * l)\n",
    "        smooth = self.avgLoss / (1 - (self.beta ** self.batchNum))\n",
    "        self.losses.append(smooth)\n",
    "\n",
    "        # compute the maximum loss stopping factor value\n",
    "        stopLoss = self.stopFactor * self.bestLoss\n",
    "\n",
    "        # check to see whether the loss has grown too large\n",
    "        if self.batchNum > 1 and smooth > stopLoss:\n",
    "            # stop returning and return from the method\n",
    "            self.model.stop_training = True\n",
    "            return\n",
    "\n",
    "        # check to see if the best loss should be updated\n",
    "        if self.batchNum == 1 or smooth < self.bestLoss:\n",
    "            self.bestLoss = smooth\n",
    "\n",
    "        # increase the learning rate ans set it as a new LR for the model training \n",
    "        lr *= self.lrMult # self.lrMult is found in the find() method\n",
    "        K.set_value(self.model.optimizer.lr, lr)\n",
    "\n",
    "    def find(self, trainData, startLR, endLR, epochs=None,\n",
    "        stepsPerEpoch=None, batchSize=32, sampleSize=2048,\n",
    "        classWeight=None, verbose=1):\n",
    "        \"\"\" following are the steps/things which is happening in this function:\n",
    "            - only using the training data for computing the loss, i.e., no split of it into test/val data \n",
    "            - loss log are transferred via LambdaCallback function to \"on_batch_end()\" fn. \n",
    "            - LR multiplier is computed once. And, it is a fixed (uniform) interval computed from endLR, startLR \n",
    "                over total numbers of batches \n",
    "            - Model's original weights and LR are temporarily saved and they get imported back again after \n",
    "              the plot for finding the best LR is done. \n",
    "        \"\"\"\n",
    "        \n",
    "        # reset our class-specific variables\n",
    "        self.reset()\n",
    "\n",
    "        # determine if we are using a data generator or not\n",
    "        useGen = self.is_data_iter(trainData)\n",
    "\n",
    "        # if we're using a generator and the steps per epoch is not\n",
    "        # supplied, raise an error\n",
    "        if useGen and stepsPerEpoch is None:\n",
    "            msg = \"Using generator without supplying stepsPerEpoch\"\n",
    "            raise Exception(msg)\n",
    "\n",
    "        # if we're not using a generator then our entire dataset must\n",
    "        # already be in memory\n",
    "        elif not useGen:\n",
    "            # grab the number of samples in the training data and\n",
    "            # then derive the number of steps per epoch\n",
    "            numSamples = len(trainData[0])\n",
    "            stepsPerEpoch = np.ceil(numSamples / float(batchSize))\n",
    "\n",
    "        # if no number of training epochs are supplied, compute the\n",
    "        # training epochs based on a default sample size\n",
    "        if epochs is None:\n",
    "            epochs = int(np.ceil(sampleSize / float(stepsPerEpoch)))\n",
    "\n",
    "        # compute the total number of batch updates that will take\n",
    "        # place while we are attempting to find a good starting\n",
    "        # learning rate\n",
    "        numBatchUpdates = epochs * stepsPerEpoch\n",
    "\n",
    "        # derive the learning rate multiplier based on the ending\n",
    "        # learning rate, starting learning rate, and total number of\n",
    "        # batch updates\n",
    "        self.lrMult = (endLR / startLR) ** (1.0 / numBatchUpdates)\n",
    "\n",
    "        # save the model's original weights, so we can reset the weights when we are \n",
    "        # done finiding the optimal learning rates \n",
    "        self.weightsFile = tempfile.mkstemp()[1]\n",
    "        self.model.save_weights(self.weightsFile)\n",
    "\n",
    "        # grab the *original* learning rate (so we can reset it\n",
    "        # later), and then set the *starting* learning rate\n",
    "        origLR = K.get_value(self.model.optimizer.lr)\n",
    "        K.set_value(self.model.optimizer.lr, startLR)\n",
    "\n",
    "        # construct a callback that will be called at the end of each\n",
    "        # batch, enabling us to increase our learning rate as training\n",
    "        # progresses\n",
    "        callback = LambdaCallback(on_batch_end=lambda batch, logs:\n",
    "            self.on_batch_end(batch, logs))\n",
    "\n",
    "        # check to see if we are using a data iterator\n",
    "        if useGen:\n",
    "            self.model.fit_generator(\n",
    "                trainData,\n",
    "                steps_per_epoch=stepsPerEpoch,\n",
    "                epochs=epochs,\n",
    "                class_weight=classWeight,\n",
    "                verbose=verbose,\n",
    "                callbacks=[callback])\n",
    "\n",
    "        # otherwise, our entire training data is already in memory\n",
    "        else:\n",
    "            # train our model using Keras' fit method\n",
    "            self.model.fit(\n",
    "                trainData[0], trainData[1],\n",
    "                batch_size=batchSize,\n",
    "                epochs=epochs,\n",
    "                class_weight=classWeight,\n",
    "                callbacks=[callback],\n",
    "                verbose=verbose)\n",
    "\n",
    "        # finally, when we are done, set back the original model's weights and LR values \n",
    "        self.model.load_weights(self.weightsFile)\n",
    "        K.set_value(self.model.optimizer.lr, origLR)\n",
    "\n",
    "    def plot_loss(self, skipBegin=10, skipEnd=1, title=\"\"):\n",
    "        # grab the learning rate and losses values to plot\n",
    "        lrs = self.lrs[skipBegin:-skipEnd]\n",
    "        losses = self.losses[skipBegin:-skipEnd]\n",
    "\n",
    "        # plot the learning rate vs. loss\n",
    "        plt.plot(lrs, losses)\n",
    "        plt.xscale(\"log\")\n",
    "        plt.xlabel(\"Learning Rate (Log Scale)\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "\n",
    "        # if the title is not empty, add it to the plot\n",
    "        if title != \"\":\n",
    "            plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the best learning rates range only at the first run of this script. \n",
    "if FIND_LR_ENABLE:\n",
    "    lrf = LearningRateFinder(model)\n",
    "    # increasing learning rates at a regular interval from a very low to very high range. Then, compute \n",
    "    # the training loss. Objective here is to find a range of LRs where the loss varies the most. That means in those \n",
    "    # LRs model is the learning the most. \n",
    "    lrf.find(train_generator, \n",
    "            startLR=1e-10, \n",
    "            endLR=1e+1, \n",
    "            epochs=20,\n",
    "            stepsPerEpoch=TRAIN_SAMPLES // BATCH_SIZE, \n",
    "            batchSize=BATCH_SIZE)\n",
    "\n",
    "    # plot the loss for the various learning rates and save the\n",
    "    # resulting plot to disk\n",
    "    lrf.plot_loss()\n",
    "    plt.savefig(LR_LOSS_PLOT_PATH)\n",
    "\n",
    "    # exit the script so we can adjust our learning rates\n",
    "    # in the config and then train the network for our full set of\n",
    "    # epochs\n",
    "    print(\"[INFO] learning rate finder complete\")\n",
    "    print(\"[INFO] examine plot and adjust learning rates before training\")\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Train model \n",
    "After finding the min and max range of the best possible learning rates, train the whole model with the following \n",
    "possibilities: \n",
    "* If ADAM is used, then set the max of the range as the starting LR. As it will adapt it gradually towards a lower value. \n",
    "  \n",
    "  \n",
    "* If SGD is used, then max of the range as the starting LR and use either default decay or polynomial decay. But be careful that decay should not go beyond the min of the range. In other words, decay should gradually reach to the min of the range. \n",
    "\n",
    "\n",
    "* If SGD with Cyclic LR is used, then use [min_lr, max_lr] as the range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 37 steps, validate for 7 steps\n",
      "Epoch 1/7\n",
      " 5/37 [===>..........................] - ETA: 1:15 - loss: 0.2578 - acc: 0.8687"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/tf_env_2.1/lib/python3.7/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/37 [============================>.] - ETA: 2s - loss: 0.3031 - acc: 0.8609\n",
      "Epoch 00001: val_acc improved from -inf to 0.82143, saving model to ./models/mobilenetv2_.h5\n",
      "37/37 [==============================] - 96s 3s/step - loss: 0.3052 - acc: 0.8609 - val_loss: 0.3883 - val_acc: 0.8214\n",
      "Epoch 2/7\n",
      "36/37 [============================>.] - ETA: 2s - loss: 0.3047 - acc: 0.8719\n",
      "Epoch 00002: val_acc did not improve from 0.82143\n",
      "37/37 [==============================] - 107s 3s/step - loss: 0.3040 - acc: 0.8716 - val_loss: 0.4439 - val_acc: 0.8013\n",
      "Epoch 3/7\n",
      "36/37 [============================>.] - ETA: 2s - loss: 0.3181 - acc: 0.8644\n",
      "Epoch 00003: val_acc did not improve from 0.82143\n",
      "37/37 [==============================] - 101s 3s/step - loss: 0.3185 - acc: 0.8652 - val_loss: 0.7516 - val_acc: 0.7210\n",
      "Epoch 4/7\n",
      "36/37 [============================>.] - ETA: 2s - loss: 0.3613 - acc: 0.8495\n",
      "Epoch 00004: val_acc improved from 0.82143 to 0.83036, saving model to ./models/mobilenetv2_.h5\n",
      "37/37 [==============================] - 94s 3s/step - loss: 0.3604 - acc: 0.8502 - val_loss: 0.3822 - val_acc: 0.8304\n",
      "Epoch 5/7\n",
      "36/37 [============================>.] - ETA: 2s - loss: 0.3161 - acc: 0.8666\n",
      "Epoch 00005: val_acc improved from 0.83036 to 0.84598, saving model to ./models/mobilenetv2_.h5\n",
      "37/37 [==============================] - 95s 3s/step - loss: 0.3156 - acc: 0.8669 - val_loss: 0.4306 - val_acc: 0.8460\n",
      "Epoch 6/7\n",
      "36/37 [============================>.] - ETA: 2s - loss: 0.3008 - acc: 0.8666\n",
      "Epoch 00006: val_acc improved from 0.84598 to 0.87723, saving model to ./models/mobilenetv2_.h5\n",
      "37/37 [==============================] - 95s 3s/step - loss: 0.3040 - acc: 0.8652 - val_loss: 0.2897 - val_acc: 0.8772\n",
      "Epoch 7/7\n",
      "36/37 [============================>.] - ETA: 2s - loss: 0.3112 - acc: 0.8614\n",
      "Epoch 00007: val_acc did not improve from 0.87723\n",
      "37/37 [==============================] - 94s 3s/step - loss: 0.3129 - acc: 0.8604 - val_loss: 0.3144 - val_acc: 0.8661\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 11144), started 0:37:47 ago. (Use '!kill 11144' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e2ba40cac5bb65a9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e2ba40cac5bb65a9\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define callbacks before starting the training\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\", verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=3, min_lr=0.00001, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(MODEL_PATH, monitor=\"val_acc\", save_best_only=True, mode='max', verbose=1)\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard = TensorBoard(log_dir=logdir, histogram_freq=1)\n",
    "#callbacks = [reduce_lr, early_stop, model_checkpoint, tensorboard]\n",
    "callbacks = [early_stop, model_checkpoint, tensorboard]\n",
    "\n",
    "# perform model training \n",
    "H = model.fit_generator(generator=train_generator, \n",
    "                    steps_per_epoch=TRAIN_SAMPLES // BATCH_SIZE, \n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=VALIDATION_SAMPLES // BATCH_SIZE, \n",
    "                    callbacks=callbacks)\n",
    "\n",
    "# launch TensorBoard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate results \n",
    "Plot Confusion matrix and classification report on both validation and test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mismatches(y_true: list, y_pred: list, filenames: list):\n",
    "    \"\"\" return a list of wrong predictions (or, mis-matches) done by the trained model \n",
    "        :param y_true: a list of true (or ground-truth) labels \n",
    "        :param y_pred: a list of predicted labels \n",
    "        :param filenames: a list of filenames corresponding to the true labels\n",
    "    \"\"\"\n",
    "    mismatches_imgs = list(dict())\n",
    "    for i in range(0, len(y_true)):\n",
    "        if y_true[i] != y_pred[i]:\n",
    "            print(f\"True class: {LABELS[y_true[i]]}({y_true[i]}) and predicted as: {LABELS[y_pred[i]]}({y_pred[i]})\")\n",
    "            temp = dict()\n",
    "            temp[\"filename\"] = filenames[i]\n",
    "            temp[\"true label\"] = y_true[i]\n",
    "            temp[\"pred label\"] = y_pred[i]\n",
    "            mismatches_imgs.append(temp)\n",
    "        continue\n",
    "    return mismatches_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot confusion matrix, classification report and mis-matches information for the validation data\n",
    "y_pred = model.predict_generator(validation_generator, steps=VALIDATION_SAMPLES // BATCH_SIZE + 1)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_true=validation_generator.classes, y_pred=y_pred))\n",
    "print(\"-\"*50)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_true=validation_generator.classes, y_pred=y_pred, target_names=LABELS))\n",
    "print(\"Mismatches information:\")\n",
    "print(get_mismatches(validation_generator.classes, y_pred, validation_generator.filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly, plot confusion for the test dataset\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DATA_DIR,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix, classification report and mis-classification (or, mis-matches) information for the test data\n",
    "y_pred = model.predict_generator(test_generator, steps=TEST_SAMPLES // BATCH_SIZE + 1)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_true=test_generator.classes, y_pred=y_pred))\n",
    "print(\"-\"*50)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_true=test_generator.classes, y_pred=y_pred, target_names=LABELS))\n",
    "print(\"Mismatches information:\")\n",
    "print(get_mismatches(test_generator.classes, y_pred, validation_generator.filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
