{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D, Activation\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import LambdaCallback \n",
    "from tensorflow.keras import backend as K \n",
    "import tempfile \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration parameters \n",
    "TRAIN_DATA_DIR = '/Users/sanchit/Documents/Projects/Datasets/fire_and_smoke_data/train/'\n",
    "VALIDATION_DATA_DIR = '/Users/sanchit/Documents/Projects/Datasets/fire_and_smoke_data/val/'\n",
    "TEST_DATA_DIR = '/Users/sanchit/Documents/Projects/Datasets/fire_and_smoke_data/test/'\n",
    "MODEL_PATH = \"./models/mobilenetv2_.h5\"\n",
    "TRAIN_SAMPLES = 1600\n",
    "VALIDATION_SAMPLES = 430\n",
    "TEST_SAMPLES = 430\n",
    "NUM_CLASSES = 2\n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20\n",
    "LABELS = [\"fire\", \"nofire\"]\n",
    "LR_LOSS_PLOT_PATH = \"./models/lr_loss_plot.png\"\n",
    "INIT_LR = 0.055 # this needs to be set as the max LR from the finding LR plot\n",
    "FIND_LR_ENABLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data generators\n",
    "create data generators for both training and validation sets and apply data augmentation only to training generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1600 images belonging to 2 classes.\n",
      "Found 430 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# create training data generator and initialize it with data augmentation methods \n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input, \n",
    "                                   horizontal_flip=True, \n",
    "                                   vertical_flip=True,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   brightness_range=[0.6, 1.3], \n",
    "                                   zoom_range=0.15, fill_mode=\"reflect\")\n",
    "\n",
    "# and validation data generator\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DATA_DIR,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=12345,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    VALIDATION_DATA_DIR,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model \n",
    "we are using transfer learning for training our model, therefore, freeze the main layers of the model and attach a new custom F.C. classifier on the top of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a model \n",
    "def create_model():\n",
    "    base_model = MobileNetV2(include_top=False, \n",
    "                              input_shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "    \n",
    "    for layer in base_model.layers[:]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    input_layer = base_model.output \n",
    "    x = GlobalAveragePooling2D()(input_layer)\n",
    "    x = Dense(128, activation='selu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(NUM_CLASSES, name=\"last_dense\")(x)\n",
    "    output = Activation(\"softmax\", name=\"last_softmax\")(x)\n",
    "    #output = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "    \n",
    "    # create the final model \n",
    "    model = Model(inputs = base_model.input, outputs = output)\n",
    "    model.summary()\n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_pad (ZeroPadding2D)       (None, 225, 225, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, 112, 112, 32) 864         Conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalization)   (None, 112, 112, 32) 128         Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)               (None, 112, 112, 32) 0           bn_Conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (Depthw (None, 112, 112, 32) 288         Conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (Bat (None, 112, 112, 32) 128         expanded_conv_depthwise[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (R (None, 112, 112, 32) 0           expanded_conv_depthwise_BN[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)  (None, 112, 112, 16) 512         expanded_conv_depthwise_relu[0][0\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (Batch (None, 112, 112, 16) 64          expanded_conv_project[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)         (None, 112, 112, 96) 1536        expanded_conv_project_BN[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormali (None, 112, 112, 96) 384         block_1_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)      (None, 112, 112, 96) 0           block_1_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_pad (ZeroPadding2D)     (None, 113, 113, 96) 0           block_1_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseCon (None, 56, 56, 96)   864         block_1_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNorm (None, 56, 56, 96)   384         block_1_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)   (None, 56, 56, 96)   0           block_1_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)        (None, 56, 56, 24)   2304        block_1_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project_BN (BatchNormal (None, 56, 56, 24)   96          block_1_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)         (None, 56, 56, 144)  3456        block_1_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_2_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_2_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise (DepthwiseCon (None, 56, 56, 144)  1296        block_2_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_BN (BatchNorm (None, 56, 56, 144)  576         block_2_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_relu (ReLU)   (None, 56, 56, 144)  0           block_2_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project (Conv2D)        (None, 56, 56, 24)   3456        block_2_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project_BN (BatchNormal (None, 56, 56, 24)   96          block_2_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_add (Add)               (None, 56, 56, 24)   0           block_1_project_BN[0][0]         \n",
      "                                                                 block_2_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand (Conv2D)         (None, 56, 56, 144)  3456        block_2_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_3_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_3_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_pad (ZeroPadding2D)     (None, 57, 57, 144)  0           block_3_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise (DepthwiseCon (None, 28, 28, 144)  1296        block_3_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_BN (BatchNorm (None, 28, 28, 144)  576         block_3_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_relu (ReLU)   (None, 28, 28, 144)  0           block_3_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project (Conv2D)        (None, 28, 28, 32)   4608        block_3_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project_BN (BatchNormal (None, 28, 28, 32)   128         block_3_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand (Conv2D)         (None, 28, 28, 192)  6144        block_3_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_4_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_4_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_4_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_4_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_4_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project (Conv2D)        (None, 28, 28, 32)   6144        block_4_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project_BN (BatchNormal (None, 28, 28, 32)   128         block_4_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_add (Add)               (None, 28, 28, 32)   0           block_3_project_BN[0][0]         \n",
      "                                                                 block_4_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand (Conv2D)         (None, 28, 28, 192)  6144        block_4_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_5_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_5_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_5_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_5_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_5_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project (Conv2D)        (None, 28, 28, 32)   6144        block_5_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project_BN (BatchNormal (None, 28, 28, 32)   128         block_5_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_5_add (Add)               (None, 28, 28, 32)   0           block_4_add[0][0]                \n",
      "                                                                 block_5_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand (Conv2D)         (None, 28, 28, 192)  6144        block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_6_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_6_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_pad (ZeroPadding2D)     (None, 29, 29, 192)  0           block_6_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise (DepthwiseCon (None, 14, 14, 192)  1728        block_6_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_BN (BatchNorm (None, 14, 14, 192)  768         block_6_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_relu (ReLU)   (None, 14, 14, 192)  0           block_6_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project (Conv2D)        (None, 14, 14, 64)   12288       block_6_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project_BN (BatchNormal (None, 14, 14, 64)   256         block_6_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand (Conv2D)         (None, 14, 14, 384)  24576       block_6_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_7_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_7_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_7_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_7_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_7_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project (Conv2D)        (None, 14, 14, 64)   24576       block_7_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project_BN (BatchNormal (None, 14, 14, 64)   256         block_7_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_add (Add)               (None, 14, 14, 64)   0           block_6_project_BN[0][0]         \n",
      "                                                                 block_7_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand (Conv2D)         (None, 14, 14, 384)  24576       block_7_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_8_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_8_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_8_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_8_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_8_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project (Conv2D)        (None, 14, 14, 64)   24576       block_8_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project_BN (BatchNormal (None, 14, 14, 64)   256         block_8_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_8_add (Add)               (None, 14, 14, 64)   0           block_7_add[0][0]                \n",
      "                                                                 block_8_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand (Conv2D)         (None, 14, 14, 384)  24576       block_8_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_9_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_9_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_9_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_9_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_9_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project (Conv2D)        (None, 14, 14, 64)   24576       block_9_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project_BN (BatchNormal (None, 14, 14, 64)   256         block_9_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_9_add (Add)               (None, 14, 14, 64)   0           block_8_add[0][0]                \n",
      "                                                                 block_9_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand (Conv2D)        (None, 14, 14, 384)  24576       block_9_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_BN (BatchNormal (None, 14, 14, 384)  1536        block_10_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_relu (ReLU)     (None, 14, 14, 384)  0           block_10_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise (DepthwiseCo (None, 14, 14, 384)  3456        block_10_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_BN (BatchNor (None, 14, 14, 384)  1536        block_10_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           block_10_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project (Conv2D)       (None, 14, 14, 96)   36864       block_10_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project_BN (BatchNorma (None, 14, 14, 96)   384         block_10_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand (Conv2D)        (None, 14, 14, 576)  55296       block_10_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_11_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_11_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_11_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_11_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_11_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project (Conv2D)       (None, 14, 14, 96)   55296       block_11_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project_BN (BatchNorma (None, 14, 14, 96)   384         block_11_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_add (Add)              (None, 14, 14, 96)   0           block_10_project_BN[0][0]        \n",
      "                                                                 block_11_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand (Conv2D)        (None, 14, 14, 576)  55296       block_11_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_12_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_12_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_12_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_12_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_12_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project (Conv2D)       (None, 14, 14, 96)   55296       block_12_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project_BN (BatchNorma (None, 14, 14, 96)   384         block_12_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_12_add (Add)              (None, 14, 14, 96)   0           block_11_add[0][0]               \n",
      "                                                                 block_12_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand (Conv2D)        (None, 14, 14, 576)  55296       block_12_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_13_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_13_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_pad (ZeroPadding2D)    (None, 15, 15, 576)  0           block_13_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise (DepthwiseCo (None, 7, 7, 576)    5184        block_13_pad[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_BN (BatchNor (None, 7, 7, 576)    2304        block_13_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)    0           block_13_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project (Conv2D)       (None, 7, 7, 160)    92160       block_13_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project_BN (BatchNorma (None, 7, 7, 160)    640         block_13_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand (Conv2D)        (None, 7, 7, 960)    153600      block_13_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_14_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_14_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_14_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_14_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_14_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project (Conv2D)       (None, 7, 7, 160)    153600      block_14_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project_BN (BatchNorma (None, 7, 7, 160)    640         block_14_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_add (Add)              (None, 7, 7, 160)    0           block_13_project_BN[0][0]        \n",
      "                                                                 block_14_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand (Conv2D)        (None, 7, 7, 960)    153600      block_14_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_15_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_15_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_15_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_15_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_15_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project (Conv2D)       (None, 7, 7, 160)    153600      block_15_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project_BN (BatchNorma (None, 7, 7, 160)    640         block_15_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_15_add (Add)              (None, 7, 7, 160)    0           block_14_add[0][0]               \n",
      "                                                                 block_15_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand (Conv2D)        (None, 7, 7, 960)    153600      block_15_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_16_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_16_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_16_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_16_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_16_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project (Conv2D)       (None, 7, 7, 320)    307200      block_16_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project_BN (BatchNorma (None, 7, 7, 320)    1280        block_16_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 7, 7, 1280)   409600      block_16_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)   5120        Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "out_relu (ReLU)                 (None, 7, 7, 1280)   0           Conv_1_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 1280)         0           out_relu[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          163968      global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "last_dense (Dense)              (None, 2)            258         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "last_softmax (Activation)       (None, 2)            0           last_dense[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 2,422,210\n",
      "Trainable params: 164,226\n",
      "Non-trainable params: 2,257,984\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create model \n",
    "model = create_model()\n",
    "\n",
    "# choose an optimize. Note for finding the best LR, it does not matter what lr is set \n",
    "# here! because during finding, it will going to set its own LRs, however, at the end, \n",
    "# it will set back this original LRs. \n",
    "#opt = tf.keras.optimizers.Adam(lr=INIT_LR)\n",
    "opt = tf.keras.optimizers.SGD()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningRateFinder:\n",
    "    \"\"\" Objective is to find a best learning rate by plotting various losses against a list of learning \n",
    "    rates which range from very high to very low. Optimal LR should lie somewhere inside of this range. \n",
    "    \n",
    "    Starting and ending LRs which are chosen are too low (where network is unable to learn, thus a high \n",
    "    loss and too high (where loss is also high), respectively). Therefore, a good range of min and max LR \n",
    "    bounds should be somewhere inside of this range and finding that good range is the objective of this class. \n",
    "    \n",
    "    At the end, entire network can be then trained by using either the correct LR (min LR) or min and max LRs \n",
    "    with a Cyclic LR scheduler. \n",
    "    \n",
    "    Reference: https://www.pyimagesearch.com/2019/08/05/keras-learning-rate-finder/\n",
    "    \"\"\"\n",
    "    def __init__(self, model, stopFactor=4, beta=0.98):\n",
    "        \"\"\" initializes variables for finding the LRs \n",
    "            \n",
    "            :param model: model for which LRs and losses are plotted and analyzed \n",
    "            :param stopFactor: stop factor when the LR becomes too large, then stop the model training automatically \n",
    "            :param beta: used for averaging the loss value \n",
    "            :param lrs: a list of tried LR values \n",
    "            :param losses: a list of tried loss values \n",
    "            :param avgLoss: average loss value over time \n",
    "            :param batchNum: current batch number \n",
    "            :param bestLoss: best loss (of course, lowest) found so far during training \n",
    "            :param lrMult: LR multiplication factor \n",
    "            :weightsFile: filename to save initial (original) weights of the model \n",
    "        \"\"\"\n",
    "        \n",
    "        # store the model, stop factor, and beta value (for computing\n",
    "        # a smoothed, average loss)\n",
    "        self.model = model\n",
    "        self.stopFactor = stopFactor\n",
    "        self.beta = beta\n",
    "\n",
    "        # initialize our list of learning rates and losses,\n",
    "        # respectively\n",
    "        self.lrs = []\n",
    "        self.losses = []\n",
    "\n",
    "        # initialize our learning rate multiplier, average loss, best\n",
    "        # loss found thus far, current batch number, and weights file\n",
    "        self.lrMult = 1\n",
    "        self.avgLoss = 0\n",
    "        self.bestLoss = 1e9\n",
    "        self.batchNum = 0\n",
    "        self.weightsFile = None\n",
    "\n",
    "    def reset(self):\n",
    "        # re-initialize all variables from our constructor\n",
    "        self.lrs = []\n",
    "        self.losses = []\n",
    "        self.lrMult = 1\n",
    "        self.avgLoss = 0\n",
    "        self.bestLoss = 1e9\n",
    "        self.batchNum = 0\n",
    "        self.weightsFile = None\n",
    "\n",
    "    def is_data_iter(self, data):\n",
    "        # define the set of class types we will check for\n",
    "        iterClasses = [\"NumpyArrayIterator\", \"DirectoryIterator\",\n",
    "             \"DataFrameIterator\", \"Iterator\", \"Sequence\"]\n",
    "\n",
    "        # return whether our data is an iterator\n",
    "        return data.__class__.__name__ in iterClasses\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        \"\"\"\n",
    "        - this function runs after every batch update \n",
    "        - recording of current loss values which is smothen up first \n",
    "        - recording of best loss and updating of it if a new one has been found \n",
    "        - checking if the loss has grown too much, then stop the model training \n",
    "        - setting up of a new LR for the next model training with multiplying current \n",
    "          LR with the LR-multiplier at every batch update\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        # get the current LR from the model and save to a list of LRs which have been used already \n",
    "        lr = K.get_value(self.model.optimizer.lr)\n",
    "        self.lrs.append(lr)\n",
    "\n",
    "        # grab the loss at the end of this batch, increment the total\n",
    "        # number of batches processed, compute the average average\n",
    "        # loss, smooth it, and update the losses list with the\n",
    "        # smoothed value\n",
    "        l = logs[\"loss\"] # NOTE: it contains the current loss of the training\n",
    "        self.batchNum += 1\n",
    "        self.avgLoss = (self.beta * self.avgLoss) + ((1 - self.beta) * l)\n",
    "        smooth = self.avgLoss / (1 - (self.beta ** self.batchNum))\n",
    "        self.losses.append(smooth)\n",
    "\n",
    "        # compute the maximum loss stopping factor value\n",
    "        stopLoss = self.stopFactor * self.bestLoss\n",
    "\n",
    "        # check to see whether the loss has grown too large\n",
    "        if self.batchNum > 1 and smooth > stopLoss:\n",
    "            # stop returning and return from the method\n",
    "            self.model.stop_training = True\n",
    "            return\n",
    "\n",
    "        # check to see if the best loss should be updated\n",
    "        if self.batchNum == 1 or smooth < self.bestLoss:\n",
    "            self.bestLoss = smooth\n",
    "\n",
    "        # increase the learning rate ans set it as a new LR for the model training \n",
    "        lr *= self.lrMult # self.lrMult is found in the find() method\n",
    "        K.set_value(self.model.optimizer.lr, lr)\n",
    "\n",
    "    def find(self, trainData, startLR, endLR, epochs=None,\n",
    "        stepsPerEpoch=None, batchSize=32, sampleSize=2048,\n",
    "        classWeight=None, verbose=1):\n",
    "        \"\"\" \n",
    "        - only using the training data for computing the loss, i.e., no split of it into test/val data \n",
    "        - loss log are transferred via LambdaCallback function to \"on_batch_end()\" fn. \n",
    "        - LR multiplier is computed once. And, it is a fixed (uniform) interval computed from endLR, startLR \n",
    "            over total numbers of batches \n",
    "        - Model's original weights and LR are temporarily saved and they get imported back again after \n",
    "          the plot for finding the best LR is done. \n",
    "        \"\"\"\n",
    "        \n",
    "        # reset our class-specific variables\n",
    "        self.reset()\n",
    "\n",
    "        # determine if we are using a data generator or not\n",
    "        useGen = self.is_data_iter(trainData)\n",
    "\n",
    "        # if we're using a generator and the steps per epoch is not\n",
    "        # supplied, raise an error\n",
    "        if useGen and stepsPerEpoch is None:\n",
    "            msg = \"Using generator without supplying stepsPerEpoch\"\n",
    "            raise Exception(msg)\n",
    "\n",
    "        # if we're not using a generator then our entire dataset must\n",
    "        # already be in memory\n",
    "        elif not useGen:\n",
    "            # grab the number of samples in the training data and\n",
    "            # then derive the number of steps per epoch\n",
    "            numSamples = len(trainData[0])\n",
    "            stepsPerEpoch = np.ceil(numSamples / float(batchSize))\n",
    "\n",
    "        # if no number of training epochs are supplied, compute the\n",
    "        # training epochs based on a default sample size\n",
    "        if epochs is None:\n",
    "            epochs = int(np.ceil(sampleSize / float(stepsPerEpoch)))\n",
    "\n",
    "        # compute the total number of batch updates that will take\n",
    "        # place while we are attempting to find a good starting\n",
    "        # learning rate\n",
    "        numBatchUpdates = epochs * stepsPerEpoch\n",
    "\n",
    "        # derive the learning rate multiplier based on the ending\n",
    "        # learning rate, starting learning rate, and total number of\n",
    "        # batch updates\n",
    "        self.lrMult = (endLR / startLR) ** (1.0 / numBatchUpdates)\n",
    "\n",
    "        # save the model's original weights, so we can reset the weights when we are \n",
    "        # done finiding the optimal learning rates \n",
    "        self.weightsFile = tempfile.mkstemp()[1]\n",
    "        self.model.save_weights(self.weightsFile)\n",
    "\n",
    "        # grab the *original* learning rate (so we can reset it\n",
    "        # later), and then set the *starting* learning rate\n",
    "        origLR = K.get_value(self.model.optimizer.lr)\n",
    "        K.set_value(self.model.optimizer.lr, startLR)\n",
    "\n",
    "        # construct a callback that will be called at the end of each\n",
    "        # batch, enabling us to increase our learning rate as training\n",
    "        # progresses\n",
    "        callback = LambdaCallback(on_batch_end=lambda batch, logs:\n",
    "            self.on_batch_end(batch, logs))\n",
    "\n",
    "        # check to see if we are using a data iterator\n",
    "        if useGen:\n",
    "            self.model.fit_generator(\n",
    "                trainData,\n",
    "                steps_per_epoch=stepsPerEpoch,\n",
    "                epochs=epochs,\n",
    "                class_weight=classWeight,\n",
    "                verbose=verbose,\n",
    "                callbacks=[callback])\n",
    "\n",
    "        # otherwise, our entire training data is already in memory\n",
    "        else:\n",
    "            # train our model using Keras' fit method\n",
    "            self.model.fit(\n",
    "                trainData[0], trainData[1],\n",
    "                batch_size=batchSize,\n",
    "                epochs=epochs,\n",
    "                class_weight=classWeight,\n",
    "                callbacks=[callback],\n",
    "                verbose=verbose)\n",
    "\n",
    "        # finally, when we are done, set back the original model's weights and LR values \n",
    "        self.model.load_weights(self.weightsFile)\n",
    "        K.set_value(self.model.optimizer.lr, origLR)\n",
    "\n",
    "    def plot_loss(self, skipBegin=10, skipEnd=1, title=\"\"):\n",
    "        # grab the learning rate and losses values to plot\n",
    "        lrs = self.lrs[skipBegin:-skipEnd]\n",
    "        losses = self.losses[skipBegin:-skipEnd]\n",
    "\n",
    "        # plot the learning rate vs. loss\n",
    "        plt.plot(lrs, losses)\n",
    "        plt.xscale(\"log\")\n",
    "        plt.xlabel(\"Learning Rate (Log Scale)\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "\n",
    "        # if the title is not empty, add it to the plot\n",
    "        if title != \"\":\n",
    "            plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIND_LR_ENABLE:\n",
    "    lrf = LearningRateFinder(model)\n",
    "    lrf.find(train_generator, \n",
    "            startLR=1e-10, \n",
    "            endLR=1e+1, \n",
    "            epochs=20,\n",
    "            stepsPerEpoch=TRAIN_SAMPLES // BATCH_SIZE, \n",
    "            batchSize=BATCH_SIZE)\n",
    "\n",
    "    # plot the loss for the various learning rates and save the\n",
    "    # resulting plot to disk\n",
    "    lrf.plot_loss()\n",
    "    plt.savefig(LR_LOSS_PLOT_PATH)\n",
    "\n",
    "    # gracefully exit the script so we can adjust our learning rates\n",
    "    # in the config and then train the network for our full set of\n",
    "    # epochs\n",
    "    print(\"[INFO] learning rate finder complete\")\n",
    "    print(\"[INFO] examine plot and adjust learning rates before training\")\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-a0ba73d313d3>:13: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 25 steps, validate for 6 steps\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/tf_venv_2.1/lib/python3.7/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/25 [===========================>..] - ETA: 2s - loss: 2.0362 - acc: 0.6107\n",
      "Epoch 00001: val_acc improved from -inf to 0.74740, saving model to ./models/mobilenetv2_.h5\n",
      "25/25 [==============================] - 73s 3s/step - loss: 2.0494 - acc: 0.6125 - val_loss: 1.5833 - val_acc: 0.7474\n",
      "Epoch 2/20\n",
      "24/25 [===========================>..] - ETA: 2s - loss: 2.1420 - acc: 0.7148\n",
      "Epoch 00002: val_acc improved from 0.74740 to 0.90365, saving model to ./models/mobilenetv2_.h5\n",
      "25/25 [==============================] - 71s 3s/step - loss: 2.0813 - acc: 0.7188 - val_loss: 0.4201 - val_acc: 0.9036\n",
      "Epoch 3/20\n",
      "24/25 [===========================>..] - ETA: 2s - loss: 1.4351 - acc: 0.8034\n",
      "Epoch 00003: val_acc did not improve from 0.90365\n",
      "25/25 [==============================] - 72s 3s/step - loss: 1.4327 - acc: 0.8037 - val_loss: 1.7945 - val_acc: 0.8099\n",
      "Epoch 4/20\n",
      "24/25 [===========================>..] - ETA: 2s - loss: 1.4212 - acc: 0.7975\n",
      "Epoch 00004: val_acc did not improve from 0.90365\n",
      "25/25 [==============================] - 71s 3s/step - loss: 1.4064 - acc: 0.7962 - val_loss: 0.9924 - val_acc: 0.8646\n",
      "Epoch 5/20\n",
      "24/25 [===========================>..] - ETA: 2s - loss: 1.0765 - acc: 0.8216\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.005499999970197678.\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.90365\n",
      "25/25 [==============================] - 70s 3s/step - loss: 1.1035 - acc: 0.8213 - val_loss: 2.7116 - val_acc: 0.7656\n",
      "Epoch 6/20\n",
      "24/25 [===========================>..] - ETA: 2s - loss: 1.0227 - acc: 0.8164\n",
      "Epoch 00006: val_acc did not improve from 0.90365\n",
      "25/25 [==============================] - 70s 3s/step - loss: 1.0283 - acc: 0.8169 - val_loss: 0.8397 - val_acc: 0.8724\n",
      "Epoch 7/20\n",
      " 8/25 [========>.....................] - ETA: 44s - loss: 0.8374 - acc: 0.8393WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a0ba73d313d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVALIDATION_SAMPLES\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                     callbacks=callbacks)\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/tf_venv_2.1/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tf_venv_2.1/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[0;32m/anaconda3/envs/tf_venv_2.1/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/anaconda3/envs/tf_venv_2.1/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tf_venv_2.1/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tf_venv_2.1/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tf_venv_2.1/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tf_venv_2.1/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tf_venv_2.1/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tf_venv_2.1/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tf_venv_2.1/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tf_venv_2.1/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/anaconda3/envs/tf_venv_2.1/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# define callbacks before starting the training\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\", verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=3, min_lr=0.00001, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(MODEL_PATH, monitor=\"val_acc\", save_best_only=True, mode='max', verbose=1)\n",
    "callbacks = [reduce_lr, early_stop, model_checkpoint]\n",
    "\n",
    "# perform model training \n",
    "H = model.fit_generator(generator=train_generator, \n",
    "                    steps_per_epoch=TRAIN_SAMPLES // BATCH_SIZE, \n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=VALIDATION_SAMPLES // BATCH_SIZE, \n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate results \n",
    "Plot Confusion matrix and classification report on both validation and test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mismatches(y_true: list, y_pred: list, filenames: list):\n",
    "    \"\"\" return a list of wrong predictions (or, mis-matches) done by the trained model \n",
    "        :param y_true: a list of true (or ground-truth) labels \n",
    "        :param y_pred: a list of predicted labels \n",
    "        :param filenames: a list of filenames corresponding to the true labels\n",
    "    \"\"\"\n",
    "    mismatches_imgs = list(dict())\n",
    "    for i in range(0, len(y_true)):\n",
    "        if y_true[i] != y_pred[i]:\n",
    "            print(f\"True class: {LABELS[y_true[i]]}({y_true[i]}) and predicted as: {LABELS[y_pred[i]]}({y_pred[i]})\")\n",
    "            temp = dict()\n",
    "            temp[\"filename\"] = filenames[i]\n",
    "            temp[\"true label\"] = y_true[i]\n",
    "            temp[\"pred label\"] = y_pred[i]\n",
    "            mismatches_imgs.append(temp)\n",
    "        continue\n",
    "    return mismatches_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-2e54ff642b12>:2: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "Confusion matrix:\n",
      "[[213   2]\n",
      " [ 65 150]]\n",
      "--------------------------------------------------\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fire       0.77      0.99      0.86       215\n",
      "      nofire       0.99      0.70      0.82       215\n",
      "\n",
      "    accuracy                           0.84       430\n",
      "   macro avg       0.88      0.84      0.84       430\n",
      "weighted avg       0.88      0.84      0.84       430\n",
      "\n",
      "Mismatches information:\n",
      "True class: fire(0) and predicted as: nofire(1)\n",
      "True class: fire(0) and predicted as: nofire(1)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "[{'filename': 'fire/1217.jpg', 'true label': 0, 'pred label': 1}, {'filename': 'fire/img_90.jpg', 'true label': 0, 'pred label': 1}, {'filename': 'no_fire/1005.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/1027.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/1143.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/1190.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/1215.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/1270.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/140.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/15.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/175.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/1854.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/1939.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/208.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/233.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/251.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/264.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/280.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/317.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/378.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/395.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/409.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/438.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/441.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/447 2.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/524.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/534.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/567.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/623.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/630 2.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/630.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/65 2.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/659.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/673.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/683.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/70.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/718.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/759 2.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/810.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/836.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/839.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/85.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/884.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/coast_nat643.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/coast_nat745.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/coast_sun33.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/coast_sun7.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/forest_cdmc283.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/forest_cdmc556.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/forest_nat1097.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/forest_nat835.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/img_1030.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/img_1053.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/img_2089.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/img_415.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/img_68.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/img_700.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/img_74.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/img_80.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/img_967.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/mountain_n44031.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/mountain_sharp66.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/opencountry_land276.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/street_urb661.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/street_urban996.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/tallbuilding_a487045.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/tallbuilding_urban28.jpg', 'true label': 1, 'pred label': 0}]\n"
     ]
    }
   ],
   "source": [
    "# Plot confusion matrix, classification report and mis-matches information for the validation data\n",
    "y_pred = model.predict_generator(validation_generator, steps=VALIDATION_SAMPLES // BATCH_SIZE + 1)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_true=validation_generator.classes, y_pred=y_pred))\n",
    "print(\"-\"*50)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_true=validation_generator.classes, y_pred=y_pred, target_names=LABELS))\n",
    "print(\"Mismatches information:\")\n",
    "print(get_mismatches(validation_generator.classes, y_pred, validation_generator.filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 430 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Similarly, plot confusion for the test dataset\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DATA_DIR,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[211   4]\n",
      " [ 82 133]]\n",
      "--------------------------------------------------\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fire       0.72      0.98      0.83       215\n",
      "      nofire       0.97      0.62      0.76       215\n",
      "\n",
      "    accuracy                           0.80       430\n",
      "   macro avg       0.85      0.80      0.79       430\n",
      "weighted avg       0.85      0.80      0.79       430\n",
      "\n",
      "Mismatches information:\n",
      "True class: fire(0) and predicted as: nofire(1)\n",
      "True class: fire(0) and predicted as: nofire(1)\n",
      "True class: fire(0) and predicted as: nofire(1)\n",
      "True class: fire(0) and predicted as: nofire(1)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "True class: nofire(1) and predicted as: fire(0)\n",
      "[{'filename': 'fire/34.jpg', 'true label': 0, 'pred label': 1}, {'filename': 'fire/5.jpg', 'true label': 0, 'pred label': 1}, {'filename': 'fire/629.jpg', 'true label': 0, 'pred label': 1}, {'filename': 'fire/998.jpg', 'true label': 0, 'pred label': 1}, {'filename': 'no_fire/1027.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/1046.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/109.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/1155.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/1362.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/1371.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/1393.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/14.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/1440.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/151.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/1522.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/1523.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/1607.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/1632.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/166.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/1854.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/233.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/31.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/330.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/362.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/378.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/386 2.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/395.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/426.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/441.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/452.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/46.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/487.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/524.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/534.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/60.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/612.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/623.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/630 2.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/630.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/65 2.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/673.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/683.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/718.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/738.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/743.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/757.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/759 2.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/762.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/844.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/864.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/884.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/926.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/coast_bea24.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/coast_cdmc821.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/coast_cdmc929.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/coast_n286045.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/coast_n291075.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/coast_n708050.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/coast_nat1043.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/coast_nat202.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/coast_nat472.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/coast_nat643.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/coast_nat897.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/coast_nat921.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/coast_natu130.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/coast_natu399.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/coast_sun11.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/forest_cdmc283.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/forest_cdmc377.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/forest_nat1184.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/highway_nat546.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/img_2089.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/mountain_n295042.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/mountain_n44031.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/mountain_nat801.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/mountain_nat891.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/opencountry_cdmc354.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/opencountry_fie43.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/opencountry_land276.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/opencountry_land291.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/street_hexp12.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/street_urb661.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/street_urb866.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/tallbuilding_art733.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/tallbuilding_urb325.jpg', 'true label': 1, 'pred label': 0}, {'filename': 'no_fire/tallbuilding_urban28.jpg', 'true label': 1, 'pred label': 0}]\n"
     ]
    }
   ],
   "source": [
    "# Plot confusion matrix, classification report and mis-classification (or, mis-matches) information for the test data\n",
    "y_pred = model.predict_generator(test_generator, steps=TEST_SAMPLES // BATCH_SIZE + 1)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_true=test_generator.classes, y_pred=y_pred))\n",
    "print(\"-\"*50)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_true=test_generator.classes, y_pred=y_pred, target_names=LABELS))\n",
    "print(\"Mismatches information:\")\n",
    "print(get_mismatches(test_generator.classes, y_pred, validation_generator.filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
