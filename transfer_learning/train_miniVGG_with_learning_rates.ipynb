{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Shallow Network - miniVGG \n",
    "With batch normalization and (optional) random cropping of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 224, 224\n",
    "train_data_dir = '/home/sanchit/Documents/Projects/datasets/fire_and_smoke_data/train/'\n",
    "validation_data_dir = '/home/sanchit/Documents/Projects/datasets/fire_and_smoke_data/val/'\n",
    "nb_train_samples = 2400\n",
    "nb_validation_samples = 490\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "model_path = \"./models/cust_network.h5\"\n",
    "init_lr = 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "input_shape = (img_width, img_height, 3)\n",
    "model.add(Conv2D(32, (3, 3), padding='same', kernel_initializer='he_normal', \n",
    "                 kernel_regularizer=l2(1e-4), input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', strides=2, kernel_initializer='he_normal', \n",
    "                 kernel_regularizer=l2(1e-4), input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', kernel_initializer='he_normal', \n",
    "                 kernel_regularizer=l2(1e-4), input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', strides=2, kernel_initializer='he_normal', \n",
    "                 kernel_regularizer=l2(1e-4), input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', kernel_initializer='he_normal', \n",
    "                 kernel_regularizer=l2(1e-4), input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', strides=2, kernel_initializer='he_normal', \n",
    "                 kernel_regularizer=l2(1e-4), input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal', \n",
    "                 kernel_regularizer=l2(1e-4), input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', strides=2, kernel_initializer='he_normal', \n",
    "                 kernel_regularizer=l2(1e-4), input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal', \n",
    "                 kernel_regularizer=l2(1e-4), input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', strides=2, kernel_initializer='he_normal', \n",
    "                 kernel_regularizer=l2(1e-4), input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opt = SGD(lr=init_lr, momentum=0.9) # 93.33%\n",
    "#opt = SGD(lr=init_lr, momentum=0.9, decay=init_lr) # 88.96 %\n",
    "#opt = Adam() # 94.17 %\n",
    "#opt = RMSprop() #  %\n",
    "opt = SGD()\n",
    "#opt = Adam(learning_rate=init_lr) # 93.12 %\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dir_path=\"\", class_mode='binary', classes=None):\n",
    "    \"\"\"\n",
    "    loads all the images for all the classes (sub-dirs) provided in the input directory.\n",
    "    :param dir_path -  input directory which contains for each class a sub-directory. \n",
    "    :param class_mode - binary (for usage in binary_crossentropy loss) and categorical (categorical_crossentropy loss)\n",
    "    :params classes - a list of classes'names \n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    data_kind = dir_path.split(\"/\")[-2] # either training or validation or testing\n",
    "    directories=[d for d in os.listdir(dir_path) if os.path.isdir(d) or (not d.startswith(\".\"))]\n",
    "    \n",
    "    for label, class_name in enumerate(directories):\n",
    "        print(f\"loading {data_kind} data for class: {class_name}\")\n",
    "        class_dir = os.path.join(dir_path, class_name)\n",
    "        for img_path in tqdm(glob(class_dir + '/*.jpg')):\n",
    "            img = load_img(img_path, target_size=(img_width, img_height))\n",
    "            img = img_to_array(img)\n",
    "\n",
    "            # save the image and its corresponding label\n",
    "            X.append(img)\n",
    "            y.append(label)\n",
    "                \n",
    "    X = np.asarray(X, dtype=np.float32) / 255.0\n",
    "    y = np.asarray(y)\n",
    "    \n",
    "    if class_mode == \"categorical\":\n",
    "        y = to_categorical(y_train, num_classes=classes)\n",
    "        \n",
    "    print(f\"total number of images loaded: {X.shape[0]} and of shape: {X.shape[1:]}\")\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_data(dir_path=train_data_dir)\n",
    "X_val, y_val = load_data(dir_path=validation_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a train generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True, \n",
    "    vertical_flip=True,\n",
    "    rotation_range=30,\n",
    "    fill_mode=\"wrap\",\n",
    "    height_shift_range=0.15,\n",
    "    width_shift_range=0.15)\n",
    "\n",
    "# create a test/val generator\n",
    "test_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size, shuffle=True)\n",
    "validation_generator = test_datagen.flow(X_val, y_val, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define callbacks before starting the training\n",
    "# early_stop = EarlyStopping(monitor=\"val_loss\", patience=10, mode=\"min\", verbose=1)\n",
    "# model_checkpoint = ModelCheckpoint(model_path, monitor=\"val_accuracy\", save_best_only=True, mode='max', verbose=1)\n",
    "# logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "# tensorboard = TensorBoard(log_dir=logdir, histogram_freq=1)\n",
    "# callbacks = [early_stop, model_checkpoint, tensorboard]\n",
    "\n",
    "H = model.fit_generator(train_generator, \n",
    "                        steps_per_epoch=nb_train_samples // batch_size, \n",
    "                        epochs=epochs,\n",
    "                        validation_data=validation_generator,\n",
    "                        validation_steps=nb_validation_samples // batch_size, \n",
    "                        workers = 8)\n",
    "\n",
    "# launch TensorBoard\n",
    "#%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = np.arange(0, epochs)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(N, H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(N, H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
